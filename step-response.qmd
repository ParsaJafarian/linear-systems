---
title: Step Response

execute:
  echo: false
  freeze: true
  cache: true
---

In the [previous lecture](freq-modeling.qmd), we saw that we can use the pole zero plot to determine if a system is BIBO stability. We also saw that we can compute the step reponse using inverse LTs. In this lecture, we will develop a heuristic method to approximate the step response from a pole-zero plot. 

```{julia}
#| output: false
# Install packages

# using Pkg; Pkg.activate(".")
# for pkg in ["IJulia", "Revise", "ControlSystems", "Plots", "LaTeXStrings", "DataFrames", "JSON"]
#    Pkg.add(pkg)
# end
# 
# # Installing Jupyter Cache
# Pkg.add("Conda")
# using Conda
# Conda.add("jupyter-cache")

using Revise

using ControlSystems, Plots, LaTeXStrings

current_theme = :bright
current_colors = theme_palette(current_theme)
theme(current_theme)
default(linewidth=2)

```

## Step response from pole-zero plot

To understand how to infer the step response from the pole-zero plot, let's revisit [the example from last lecture]:

![Block diagram for a simple LTI system](figures/svg/step-response-block-diagrams1.svg){#fig-ex-motivating}

[the example from last lecture]: freq-modeling.qmd#step-response

Recall that we simplified the partial fraction expansion as
$$ \frac{\frac12}{s} - \frac{\frac12}{s+2}.$$

Consequently, the step response (which is the inverse LT of the above) is:
$$
\Bigl[ \underbrace{\frac 12}_{\text{Forced response}} 
-
\underbrace{\frac 12 e^{-2t}}_{\text{Natural response}}
\Bigr] \mathbb{1}(t).
$$

The salient features of the step response are:

- The pole of the input generates a **forced** response.
- The pole of the system TF generates a **natural** response.
- The **amplitude** of the response depends on the exact values of the poles and zeros, but the **form** of the response only depends on the location of the poles.

Thus, even without doing any exact partial fraction expansion, we know that
$$
\dfrac{1}{s(s+2)} = \frac{K_1}{s} + \frac{K_2}{s+2}.
$$
Thus, we know that the output will be of the form:
$$
c(t) = \bigl[ K_1 + K_2 e^{-2t} \bigr] \mathbb{1}(t).
$$

Thus, we can obtain the **form** of the output without any explicit calculations.

:::{#exr-step-response-form}
Find the general form of the step response of the following systems:

a. $\displaystyle
G(s) = \frac{ s + 2 } { (s+5)(s+10) }.$
b. $\displaystyle
G(s) = \frac{ 5(s+3)(s+10) }{ (s+1)(s+5)(s+20) }.$
:::

:::{.callout-note collapse="true"} 
#### Solution

a. $c(t) = \bigl[
K_1 + K_2 e^{-5t} + K_3 e^{-10t} 
\bigr] \mathbb{1}(t).$

b. $c(t) = \bigl[
K_1 + K_2 e^{-t} + K_3 e^{-5t}  + K_4 e^{-20t}
\bigr] \mathbb{1}(t).$

:::

## DC Gain

In the above examples, the system does not have a pole at origin. Such systems are called **type 0** systems. For stable type 0 systems, the step response always settles to a steady state value known as the **DC gain**. For a type 0 system with TF $G(s)$, the DC gain is given by
$$
\text{DC-gain} = G(0).
$$

We will expand more on this point later in the course.

## Dominant poles and approximate system response

Now we compare the step response of two systems

- $G_1(s) = \dfrac{1}{(s+2)}$
- $G_2(s) = \dfrac{20}{(s+2)(s+20)}$.

Note that both systems are stable type 0 systems with a DC gain of $0.5$. So, we expect them to settle at a steady state value of $0.5$.

```{julia}
#| label: fig-dominant-pole
#| fig-cap: Step response of $G_1(s)$ and $G_2(s)$.

using ControlSystems, Plots

G1 = zpk([],[-2],1)
G2 = zpk([],[-2,-20],20)

T = 10 

plt = plot(size=(600,300))
plot!(plt, step(G1, T), label=L"G_1(s)")
plot!(plt, step(G2, T), label=L"G_2(s)")
```

The step responses of both systems are very close. Thus, we can approximate $G_2(s)$ by $G_1(s)$. Let's look at the partial fraction expansion to see what is happening.

- $\displaystyle
C_1(s) = \frac{1}{s(s+2)} = \frac{0.5}{s} - \frac{0.5}{s+2}.$

- $\displaystyle
C_2(s) = \frac{20}{s(s+2)(s+20)}
= \frac{0.5}{s} - \frac{0.55}{s+2} + \frac{0.055}{s+20}.$

Note that the first two terms of $C_2(s)$ are almost the same as $C_1(s)$. Why is the third term $0.055/(s+20)$ negligible? The factor $0.055$ is small, but that is not the main reason for the third term to be small. To see what is happening, let's compute the inverse LTs:

- $c_1(t) = [ 0.5 - 0.5 e^{-2t} ] \mathbb{1}(t).$
- $c_2(t) = [0.5 - 0.55 e^{-2t} + 0.055 e^{-20t}.$

The reason that we can ignore $0.55/(s+20)$ is that $e^{-20t}$ decays much faster than $e^{-2t}$. In particular, at $t=1$, 

- $e^{-2t} \approx 0.1353$
- $e^{-20t} \approx 2.06 \times 10^{-9}$.

```{julia}
#| label: fig-exponential
#| fig-cap: Decaying exponentials

t = 0:0.001:1

plt = plot(size=(600,300))
plot!(plt, t, exp.(-2t), label=L"e^{-2t}")
plot!(plt, t, exp.(-20t), label=L"e^{-20t}")
```

In this example, we say that in system $G_2(s)$ the pole at $p_1 = -2$ **dominates** the pole at $p_2 = -20$. 
In this course, we will follow the heuristic that pole $p_1$ dominates pole $p_2$ if
\begin{equation}\label{eq:dominant-pole}
\ABS{\text{Re}(p_1)} \ge 
\frac 1{5} \ABS{\text{Re}(p_2)}.
\end{equation}

**Dominant pole approximation** refers to the approximate system where the _dominated_ poles are removed. In particular, to obtain a dominant pole approximation of a system with poles $\{p_1, \dots, p_n\}$, we split the poles into two sets $\mathcal P_d = \{p_1, \dots, p_k\}$ and $\mathcal P_r = \{p_{k+1}, \dots, p_n\}$ which has the following property: every pole $p_i$ in $\mathcal P_d$ dominates every pole $p_j$ in $\mathcal P_r$. Then, the dominant pole approximation ignores all the poles in the set $\mathcal P_r$. 

:::{#exm-dominant-pole-approximation-1}
Consider the system
$$
  G_1(s) = \frac{10}{(s+1)(s+2)(s+10)}.
$$
In this case, the pole at $-10$ is dominated by both poles $\{-1,-2\}$. Thus, the pole at $-10$ can be ignored and the simplified system is
$$
  \tilde G_1(s) = \frac{1}{(s+1)(s+2)}.
$$

_Note_: Note that we have picked the gain of $\tilde G_1(s)$ so that $G_1(s)$ and $\tilde G_1(s)$ have the same DC gain.

We can confirm this result by comparing the step responses:

```{julia}
#| label: fig-exm-dominant-pole-1
#| fig-cap: Step response of $G(s)$ and $\tilde G(s)$ in @exm-dominant-pole-approximation-1

using ControlSystems, Plots

G1 = zpk([],[-1,-2,-10],10)
G2 = zpk([],[-1,-2],1)

T = 5 

plt = plot(size=(600,300))
plot!(plt, step(G1, T), label=L"G_1(s)")
plot!(plt, step(G2, T), label=L"\tilde G_1(s)")
```

:::

:::{#exm-dominant-pole-approximation-2}
Consider the system
$$
  G_2(s) = \frac{10}{(s+1)(s+4)(s+10)}.
$$
In this case, we cannot ignore any pole. Note that the pole at $-1$ **does not dominate** the pole at $-4$, and the pole at $-4$ **does not dominate** the pole at $-10$.  Thus, we cannot partition the poles into two sets such that one set dominates the other. Thus, the above system **cannot** be simplied to
$$
  \tilde G_2(s) = \frac{1}{(s+1)(s+4)}.
$$
We can confirm this result by comparing the step responses:

```{julia}
#| label: fig-exm-dominant-pole-2
#| fig-cap: Step response of $G(s)$ and $\tilde G(s)$ in @exm-dominant-pole-approximation-2

using ControlSystems, Plots

G1 = zpk([],[-1,-4,-10],10)
G2 = zpk([],[-1,-4],1)

T = 5 

plt = plot(size=(600,300))
plot!(plt, step(G1, T), label=L"G_2(s)")
plot!(plt, step(G2, T), label=L"\tilde G_2(s)")
```
:::

Wait what? Why is @fig-exm-dominant-pole-1 a good approximation while @fig-exm-dominant-pole-2 is not? Both of them look equally good or bad. This example highlights that we have to be careful with interpretting the dominant pole approximation heuristic. It says that if \eqref{eq:dominant-pole} is satisfied then we expect the approximate system to behave the same as the original system. If \eqref{eq:dominant-pole} is not satisfied, then there might be instances where the approximate system is different from the original system. For example, let's consider:
$$
  G_1(s) = \frac{10}{( (s+2)^2 + 4^2 )(s + 10) }
  \stackrel{?}{\approx}
  \tilde G_1(s) = \frac{1}{((s+2)^2 + 4^2)}
$$
versus
$$
  G_2(s) = \frac{10}{( (s+4)^2 + 8^2 )(s + 10) }
  \stackrel{?}{\approx}
  \tilde G_2(s) = \frac{1}{((s+4)^2 + 8^2)}
$$
The dominant pole approximation heuristic says that the first approximation _should_ a good approximation while the second _may_ not be. We plot the two step responses to evalaute:

```{julia}
#| label: fig-approximation-comparison
#| fig-cap: Checking the quality of approximations
using ControlSystems, Plots

G1 = zpk([],[-2+4im,-2-4im,-10],10)
G2 = zpk([],[-2+4im,-2-4im],1)

T = 5 

plt1 = plot(size=(600,150))
plot!(plt1, step(G1, T), label=L"G_1(s)")
plot!(plt1, step(G2, T), label=L"\tilde G_1(s)")

G3 = zpk([],[-4+8im,-4-8im,-10],10)
G4 = zpk([],[-4+8im,-4-8im],1)

plt2 = plot(size=(600,150))
plot!(plt2, step(G3, T), label=L"G_2(s)")
plot!(plt2, step(G4, T), label=L"\tilde G_2(s)")

plot(plt1, plt2)

```


## High-level system design idea

In the next few weeks, we will learn techniques to design system controllers so that we can place the poles of a closed loop system at any desired location. But how do we choose where we want to place the poles of the closed loop system?

Of course, the first objective is to make sure that the closed loop system is stable. However, a practical design goes beyond stability.
Suppose we are designing the cruise controller of a car and have an option of the following three controllers.

```{julia}
#| label: fig-cruise-control
#| fig-cap: Step responses of three different systems

function secondOrder(σ,ω)
  p1 = σ + im*ω
  p2 = σ - im*ω
  K  = σ^2 + ω^2
  zpk([], [p1,p2], K)
end

G1 = secondOrder(-2,4)
G2 = secondOrder(-2,10)
G3 = secondOrder(-0.5,2)

T = 5
plt = plot(size=(600,300))
plot!(plt, step(G1, T), label=L"$G_1(s)$")
plot!(plt, step(G2, T), label=L"$G_2(s)$")
plot!(plt, step(G3, T), label=L"$G_3(s)$")

```

It is clear from the above plots that the transient response of the system matters as well. For a higer order system, finding the relationship between the location of the poles and the transient response can be difficult. To circumvent this difficulty, our general design philosophy will be as follows:

- We will first understand the relationship between the location of the poles and the transient behavior of a first and second order system.
- Later, when it comes to system design, we will place the poles of the closed loop system such that the dominant pole approximation of the system is equivalent to a second order system. 

## Time response of first order systems

A general first order system is of the form
$$
\dfrac{dc(t)}{dt} + a c(t) = b r(t).
$$
By inspection, we know that the transfer function is
$$
  \frac{b}{s+a} = \frac{b}{a} \cdot \frac{a}{s+a} 
  = K \dfrac{a}{s+a}.
$$

![A general first order system](figures/svg/step-response-block-diagrams2.svg){#fig-first-order-block-diagram}

```{julia}

using ControlSystems, DataFrames

# Use Float16 to reduce the size of data passed to OJS
df=DataFrame(a=Float16[],time=Float16[],output=Float16[])

for a in 0.5:0.1:2.5
  G = zpk([],[-a],a)
  res = step(G,5)
  N = length(res.t)

  # Subsample by 5 for plotting
  for n=1:5:N
    push!(df, (a=Float16(a), time=Float16(res.t[n]), output=Float16(res.y[n])))
  end
end

ojs_define(first_order = df)
```

```{ojs}
//| layout-ncol: 2
viewof a_1 = Object.assign(Inputs.range([0.5, 2.5], {label: "a", step: 0.1, value: 1 }), {style: '--label-width:20px'})

viewof K_1 = Object.assign(Inputs.range([0.5, 1.5], {label: "K", step: 0.1, value: 1 }), {style: '--label-width:20px'})

```

```{ojs}
//| echo: false
transformed_first_order = first_order.map(d =>({...d, output: d.output*K_1}))

PZplot = function(zeros, poles, xdomain, ydomain) {
  return Plot.plot({
    grid: true,
    x: { domain: xdomain},
    y: { domain: ydomain},

    marks: [
      // Axes
      Plot.ruleX([0]),
      Plot.ruleY([0]),
      // Data
      Plot.dot(zeros, {x:"σ", y:"jω", r: 5}),
      Plot.dot(poles, {x:"σ", y:"jω", symbol: "times", r: 5}),
    ]
  })
}
```

```{ojs}
//| layout-ncol: 2
//| label: fig-first-order-step-response
//| fig-cap: Step response of a first order system for different values of the parameters

PZplot(
       [], 
       [ {σ: -a_1, jω: 0} ], 
       [-3, 3],
       [-3, 3],
      )

Plot.plot({
  grid: true,
  y: { domain: [0, 1.6] },
  x: { domain: [0,5] },
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    // a_1 is still 64 bit float while a is 16 bit float. So we do a crude comparison for equality. 
    Plot.line(transformed_first_order.filter(d => Math.abs(d.a - a_1) <= 0.01), 
              {x:"time", y:"output", stroke: "darkblue" })
  ]
})
```

We can compute the step response by the usual partial fraction expansion:
$$ C(s) = K \frac{a}{s+a} = K \biggl[ \frac{1}{s} - \frac{1}{s+a}\biggr]. $$
Taking inverse LTs, we get:
$$ c(t) = K \bigl[ 1 - e^{-at} \bigr] \mathbb{1}(t). $$ 

### Important characteristics of the step response

The response of a first order system has the following features:

- There is no overshoot
- The initial slope (at $t=0$) is non-zero and equal to $a$. 

#### Time constant $τ$

- The parameter $τ = 1/a$ is called the **time constant** of a first order system. 
- The intial slope of the step response is $a$ (i.e., $1/τ$).
- At $t=τ$, $c(τ) = K(1-e^{-1}) \approx 63\%$ of final value.

#### Rise time $T_r$

- The rise time, denoted by $T_r$ is the time to go from $10\%$ to $90\%$ of the final value. 

- To find time $t_1$ when the response reaches $10\%$ of the final value:
  $$
    c(t_1) = 1 - e^{-a t_1} = 0.1 
    \implies
    t_1 = \frac{0.11}{a}.
  $$

- Similarly, to find time $t_2$ when the response reaches $90\%$ of the final value:
  $$
    c(t_2) = 1 - e^{-a t_2} = 0.9
    \implies
    t_2 = \frac{2.31}{a}.
  $$

- Thus, 
  $$
  \bbox[5pt,border: 1px solid]{T_r = \frac{2.31}{a} - \frac{0.11}{a} = \frac{2.2}{a}}
  $$

#### Settling time $T_s$

- The (2%) setting time is the time required for the step response to reach 2% of its final value. 

- To find $T_s$, we solve
  $$
  (1-e^{-a T_s}) = 0.98 
  \implies
  \bbox[5pt,border: 1px solid]{T_s = \frac 4a}
  $$

:::{#exm-first-order}
Consider the TF $G(s) = \dfrac{100}{s+50}$. Identify the time constant $τ$, rise time $T_r$, and settling time $T_s$. 
:::

:::{.callout-note collapse="true"} 
#### Solution

We start by writing the TF in standard form:
$$
  G(s) = 2 \frac{50}{s+50}.
$$
Comparing from the standard form, we have $K=2$ and $a=50$. Thus,

- $τ = \dfrac{1}{a} = 0.02$.
- $T_r = \dfrac{2.2}{a} = 2.2 τ = 0.044$ s.
- $T_s = \dfrac{4}{a} = 4 τ = 0.08$ s.

:::

## Identifying a first-order system via testing

In many applications, we may not know the TF of a system and may need to identify the TF from the measurements of the step response. We will do such an experiment in Lab 3. In such cases, we can identify that the system is first order from the following features:

- no overshoot
- non-zero initial slope.


For a first order system, we need to identify two parameters: $K$ and $a$.

- The gain $K$ is equal to the final value of the step response.
- To identify $a$, we identify the time constant $τ=1/a$ as the time where the step response is $0.63K$. 

Then, the TF is
$$ G(s) = K \frac{a}{s+a}. $$

:::{#exm-identify-first-order}

Identify the transfer function from the following step response

```{julia}

using ControlSystems, Plots

G = zpk([],[-4],10)

T = 2 

plt = plot(size=(600,300), gridalpha=0.75, minorgridalpha=0.25)
plot!(plt, step(G, T))
```
:::

:::{.callout-note collapse="true"} 
### Solution

Since there is no overshoot and the initial slope is non-zero, this is the step response of a first order system.

- The final DC value of response is $2.5$. Thus, $K = 2.5$.
- Now we search for the time when the response is $0.63K = 1.575$ which happens around $τ=0.25$. Thus, $a = 1/τ = 4$. 

Hence $G(s) = K \dfrac{a}{s+a} = \dfrac{10}{s+4}$.

:::

## Types of second order systems

A general second order system is of the form
$$
\frac{d^2 c(t)}{dt^2} + a_1 \frac{d c(t)}{dt} + a_0 c(t) = b_0 r(t).
$$
By inspection, we know that the transfer function is
$$
G(s) = \frac{b_0}{s^2 + a_1 s + a_0} 
=
K \frac{ω_n^2}{s^2 + 2 ζ ω_n s + ω_n^2}
$$
where $K$ is called the gain, $ω_n$ is called the _natural_ frequency and $ζ$ is called the damping coefficient When $ζ < 0$, the system is unstable and we will not discuss that case. When $ζ \ge 0$, we observe four types of behavior depending on the value of $ζ$. These are called the **categories** of a second order system:

1. **Undamped** $ζ = 0$, in which case the poles are at $\pm j ω_n$.
2. **Underdamped** $0 < ζ < 1$, in which case the poles are at 
   $-ω_n( ζ \pm j\sqrt{1 - ζ^2}).$
3. **Critically damped** $ζ = 1$, in which case there is a double pole at $-ω_n$.
4. **Overdamped** $ζ > 1$, in which case the poles are at
   $-ω_n(ζ \pm \sqrt{ζ^2 - 1}).$

@fig-damping illustrates the impact of the damping coefficient on the location of the poles:

```{julia}

using ControlSystems, DataFrames

# Use Float16 to reduce the size of data passed to OJS
df=DataFrame(ζ=Float16[],time=Float16[],output=Float16[])

for ζ in 0:0.1:5.5
  ω_d = 1
  ω_n = sqrt(ω_d^2 + ζ^2)
  G = tf([ω_n^2],[1,2*ζ*ω_n, ω_n^2])
  res = step(G,8)
  N = length(res.t)

  # Subsample by 2 for plotting
  for n=1:2:N
    push!(df, (ζ=Float16(ζ), time=Float16(res.t[n]), output=Float16(res.y[n])))
  end
end

ojs_define(second_order_zeta = df)
```


```{ojs}
  viewof zeta_damping = Object.assign(Inputs.range([0, 5.5], {label: "ζ", step: 0.1, value: 0.5 }), {style: '--label-width:20px'})

  ω_damping = 1

  poles_damping = {
    var factor
    var poles

    if (zeta_damping == 0) {
      poles = [ { σ: 0, jω: ω_damping },
                { σ: 0, jω: -ω_damping } ] 
    } else if (0 < zeta_damping && zeta_damping < 1) { 
      factor = Math.sqrt(1-zeta_damping*zeta_damping)
      poles = [ { σ: -ω_damping*zeta_damping, jω: ω_damping*factor }, 
                { σ: -ω_damping*zeta_damping, jω: -ω_damping*factor } ] 
    } else {// zeta_damping > 1
      factor = Math.sqrt(zeta_damping*zeta_damping-1)
      poles = [ { σ: -ω_damping*zeta_damping + ω_damping*factor, jω: 0 }, 
                { σ: -ω_damping*zeta_damping - ω_damping*factor, jω: 0 } ] 
    }
    return poles
  }
```

```{ojs}
//| layout-ncol: 2
//| label: fig-damping
//| fig-cap: Step response as a function of damping coefficient

PZplot(
       [], 
       poles_damping,
       [-4.5*ω_damping, 0.5*ω_damping],
       [-1.5*ω_damping, 1.5*ω_damping],
      )

Plot.plot({
  grid: true,
  y: { domain: [0, 1.6] },
  x: { domain: [0,8] },
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    // zeta_damping is still 64 bit float while a is 16 bit float. So we do a crude comparison for equality. 
    Plot.line(second_order_zeta.filter(d => Math.abs(d.ζ - zeta_damping) <= 0.01), 
              {x:"time", y:"output", stroke: "darkblue" }),
  ]
})

```

:::{#exr-2nd-order}
Indentify the category of the following second order systems:

a. $\dfrac{12}{s^2 + 8s + 12}.$
b. $\dfrac{16}{s^2 + 8s + 16}$.
c. $\dfrac{20}{s^2 + 8s + 20}$. 

:::

:::{.callout-note collapse="true"} 
#### Solution
a. $ζ = \dfrac{8}{2\sqrt{12}} \approx 1.1547$. Thus, the system is overdamped.
b. $ζ = \dfrac{8}{2\sqrt{16}} = 1$. Thus, the system is critically damped.
b. $ζ = \dfrac{8}{2\sqrt{20}} \approx 0.8944$. Thus, the system is underdamped.
:::

## Step response of undamped second order system

## Step response of underdamped second order system

<!-- TODO: Add step response details -->

### Peak Time

### Percentage overshoot

### Settling time

### Rise time

## Features of time response in terms of location of poles

### Same damped frequency

The peak time depends on the damped frequency. So, if we change $σ$ while keeping $ω_d$ fixed, the peak time of the system remains the same.

```{julia}

using ControlSystems, DataFrames

# Use Float16 to reduce the size of data passed to OJS
df=DataFrame(σ=Float16[],time=Float16[],output=Float16[])

for σ in 0.1:0.1:4
  ω_d = 2
  G = zpk([], [-σ+ω_d*im, -σ-ω_d*im], σ^2 + ω_d^2)
  res = step(G,5)
  N = length(res.t)

  # Subsample by 2 for plotting
  for n=1:2:N
    push!(df, (σ=Float16(σ), time=Float16(res.t[n]), output=Float16(res.y[n])))
  end
end

ojs_define(second_order_sigma = df)
```

```{ojs}
//| layout-ncol: 1
viewof param_sigma = Object.assign(Inputs.range([0.1,4], {label: "σ", step: 0.1, value: 2 }), {style: '--label-width:20px'})

ω_d_sigma = 2
T_p_sigma = Math.PI/ω_d_sigma
M_p_sigma = 1 + Math.exp(-param_sigma*T_p_sigma)
peak_sigma = [ {x: T_p_sigma, y: 0}, {x: T_p_sigma, y: M_p_sigma} ]

```

```{ojs}
//| layout-ncol: 2
//| label: fig-second-order-sigma
//| fig-cap: Step response of a second order system for fixed $ω_d$ and different values $σ$. The red dot shows the peak of the step response.

PZplot(
       [], 
       [ {σ: -param_sigma, jω: ω_d_sigma}, {σ: -param_sigma, jω: -ω_d_sigma} ], 
       [-3, 3],
       [-5, 5],
      )

Plot.plot({
  grid: true,
  y: { domain: [0, 1.6] },
  x: { domain: [0,5] },
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    // param_sigma is still 64 bit float while a is 16 bit float. So we do a crude comparison for equality. 
    Plot.line(second_order_sigma.filter(d => Math.abs(d.σ - param_sigma) <= 0.01), 
              {x:"time", y:"output", stroke: "darkblue" }),
    Plot.dot([ [T_p_sigma, M_p_sigma] ], {fill: "red", r:4}),
    Plot.line(peak_sigma, {x: "x", y: "y", stroke: "red"})
  ]
})
```

### Same $σ$

The settling time depends on $σ$. So, if we change $ω_d$ while keeping $σ$ fixed, the settling time of the system remains the same. 

```{julia}

using ControlSystems, DataFrames

# Use Float16 to reduce the size of data passed to OJS
df=DataFrame(ωd=Float16[],time=Float16[],output=Float16[])

for ωd in 0.1:0.1:4
  σ = 2
  G = zpk([], [-σ+ωd*im, -σ-ωd*im], σ^2 + ωd^2)
  res = step(G,5)
  N = length(res.t)

  # Subsample by 2 for plotting
  for n=1:2:N
    push!(df, (ωd=Float16(ωd), time=Float16(res.t[n]), output=Float16(res.y[n])))
  end
end

ojs_define(second_order_ωd = df)
```

```{ojs}
//| layout-ncol: 1
viewof param_ωd = Object.assign(Inputs.range([0.1,4], {label: "ωd", step: 0.1, value: 2 }), {style: '--label-width:20px'})

σ_ωd = 2

```

```{ojs}
//| layout-ncol: 2
//| label: fig-second-order-ωd
//| fig-cap: Step response of a second order system for fixed $ω_d$ and different values $σ$. The red dot shows the peak of the step response.

PZplot(
       [], 
       [ {σ: -σ_ωd, jω: param_ωd}, {σ: -σ_ωd, jω: -param_ωd} ], 
       [-3, 3],
       [-5, 5],
      )

Plot.plot({
  grid: true,
  y: { domain: [0, 1.6] },
  x: { domain: [0,5] },
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    // param_ωd is still 64 bit float while a is 16 bit float. So we do a crude comparison for equality. 
    Plot.line(second_order_ωd.filter(d => Math.abs(d.ωd - param_ωd) <= 0.01), 
              {x:"time", y:"output", stroke: "darkblue" }),
  ]
})
```

### Same damping coefficient

The peak overshoot depends on the damping coefficient. So, if we change $ω_n$ keeping $ζ$ constant, the peak overshoot (and therefore percentage overshoot) remains the same.

```{julia}

using ControlSystems, DataFrames

# Use Float16 to reduce the size of data passed to OJS
df=DataFrame(ωn=Float16[],time=Float16[],output=Float16[])

for ωn in 0.1:0.1:4
  ζ = 0.4
  G = tf([ωn^2],[1,2*ζ*ωn, ωn^2])
  res = step(G,5)
  N = length(res.t)

  # Subsample by 2 for plotting
  for n=1:2:N
    push!(df, (ωn=Float16(ωn), time=Float16(res.t[n]), output=Float16(res.y[n])))
  end
end

ojs_define(second_order_ωn = df)
```

```{ojs}
//| layout-ncol: 1
viewof param_ωn = Object.assign(Inputs.range([0.1,4], {label: "ωn", step: 0.1, value: 2 }), {style: '--label-width:20px'})

ζ_ωn = 0.4

```

```{ojs}
//| layout-ncol: 2
//| label: fig-second-order-ωn
//| fig-cap: Step response of a second order system for fixed $ω_d$ and different values $σ$. The red dot shows the peak of the step response.

PZplot(
       [], 
       [ {σ: -param_ωn*ζ_ωn, jω:  param_ωn*Math.sqrt(1 - ζ_ωn**2) },
         {σ: -param_ωn*ζ_ωn, jω: -param_ωn*Math.sqrt(1 - ζ_ωn**2) } ],
       [-3, 3],
       [-5, 5],
      )

Plot.plot({
  grid: true,
  y: { domain: [0, 1.6] },
  x: { domain: [0,5] },
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    // param_ωn is still 64 bit float while a is 16 bit float. So we do a crude comparison for equality. 
    Plot.line(second_order_ωn.filter(d => Math.abs(d.ωn - param_ωn) <= 0.01), 
              {x:"time", y:"output", stroke: "darkblue" }),
  ]
})
```


## Identifying an underdamped second order system via testing

A second order underdamped system has two characteristics:

- Oscillatory overshoots (can be hard to see for $ζ$ close to 1)
- Zero initial slope.

Note that all underdamped higher order systems share these characteristics, so it can be sometimes hard to distinguish a second order system from a higher order system. 

For a second order system, we need to identify three parameters: $K$, $ω_n$ and $ζ$. 

- The gain $K$ is equal to the final value of the step response. 
- To find $ω_n$ and $ζ$, we need to find two out the three features: peak time, percentage overshoot, and setting time. Using these features, we can identify $ω_n$ and $ζ$. 

Then, the TF is given by
$$ G(s) = K \frac{ω_n^2}{s^2 + 2 ζ ω_n s + ω_n^2}. $$

:::{#exm-identify-second-order}

Identify the transfer function from the following step response

```{julia}

using ControlSystems, Plots

G = zpk([],[-2+4im,-2-4im],40)

T = 6 

plt = plot(size=(600,300), gridalpha=0.75, minorgridalpha=0.25)
plot!(plt, step(G, T))
```
:::

:::{.callout-note collapse="true"} 
### Solution

From the step response, we can infer that this is the step response of an underdapmper second order system, which in general is of the form:
$$
  G(s) = K \frac{ω_n^2}{s^2 + 2 ζ ω_n s + ω_n^2}.
$$

We now identify the parameters:

- The final DC value of the response is $2$. Thus, $K = 2$. 

- From the plot, we see that $T_p \approx 0.75$. Thus,
  $$ ω_d = \frac{π}{T_p} = 4.188. $$

- From the plot, we see that $y_{\text{max}} = 2.4$. We have already identified that $y_{\text{final}} = 2$. Thus,
  $$ \% {\rm OS} = \frac{y_{\text{max}} - y_{\text{final}}}{y_{\text{final}}} \times 100
  = 20\%
  $$
  The formula for $\%{\rm OS}$ can be written as 
  $$
  \%{\rm OS} = \exp(-σ T_p) \times 100
  $$

  Inverting the formula, we get
  $$
  σ = \frac{-\ln(\%{\rm OS}/100)}{T_p} = 2.146
  $$

  Thus, 
  $$ ω_n^2 = σ^2 + ω_d^2 = 22.151 $$

Hence, the transfer function is 
$$
G(s) = 2 \frac{22.151}{s^2 + 4.21s + 22.151}
= \frac{44.302}{s^2 + 4.21s + 22.151}.
$$

To confirm, we plot the step response of the above system below. The plotted response is almost identical to the given response.

```{julia}
#| echo: true

using ControlSystems, Plots

G = tf([44.302],[1,4.21,22.151])

T = 6 

plt = plot(size=(600,300), gridalpha=0.75, minorgridalpha=0.25)
plot!(plt, step(G, T))
```


:::

## Impact of zeros

In the characterization of the step response of a second order underdamped system above, we assumed that the system had no zeros. The presence of a zero leads to more oscillations and the exact behavior depends on whether the zero is in the left-hand place (called minimum phase system) or right-hand plane (called non-minimum phase system), which we discuss below.

The impact of zeros means that we will not be able to execute our high-level idea of controller design because we cannot control the zeros of a closed loop system. So, in practice, we need to verify the control design via simulations to make sure that the specs are satisfied. 

### Impact of zero in the left-hand plane (minimum-phase system)

To undersand this, we compare the response of two systems
$$
  \dfrac{8}{s^2 + 4s + 8}
  \quad\hbox{vs}\quad
  8 \cdot \dfrac{1+\frac{s}{z}}{s^2 + 4s + 8}
$$

```{julia}

using ControlSystems, DataFrames

# Use Float16 to reduce the size of data passed to OJS
df=DataFrame(z=Int[],time=Float16[],output=Float16[])

for z in 0:6
  if z == 0 
    G = tf(8 .* [1], [1,4,8])
  else
    G = tf(8 .* [1/z,1], [1,4,8])
  end
  res = step(G,5)
  N = length(res.t)

  for n=1:N
    push!(df, (z=z, time=Float16(res.t[n]), output=Float16(res.y[n])))
  end
end

ojs_define(second_order_min_zero = df)
```

```{ojs}
viewof zero = Object.assign(Inputs.range([1,6], {label: "z", step: 1, value: 1 }), {style: '--label-width:20px'})
```
```{ojs}
//| layout-ncol: 2
//| label: fig-second-order-with-min-zero
//| fig-cap: Step response of a seocnd order system for different values zero. The orange curve shows the step response of a system without zero and the blue curve shows the step response of the system with zeros.

PZplot(
       [ {σ: -zero, jω: 0} ], 
       [ {σ: -2, jω: 2}, {σ: -2, jω: -2} ],
       [-6, 2],
       [-3, 3],
      )

Plot.plot({
  grid: true,
  y: { domain: [0, 1.8] },
  x: { domain: [0,5] },
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    Plot.line(second_order_min_zero.filter(d => d.z == zero), 
              {x:"time", y:"output", stroke: "darkblue" }),
    Plot.line(second_order_min_zero.filter(d => d.z == 0), 
              {x:"time", y:"output", stroke: "orange" })
  ]
})
```

The above example shows that the presence of a zero in the LHP leads to more overshoot and as the zero moves away from the dominant pole, the response approaches that of a system with no zeros. To understand why this is the case, we can view the system as
$$
  G(s) = K \frac{ω_n^2 (1 + \frac{s}{z})}{s^2 + 2 ζω_n^2 + ω_n^2}
  = 
  K \frac{ω_n^2}{s^2 + 2 ζω_n^2 + ω_n^2}
  +
  K \frac{ω_n^2}{s^2 + 2 ζω_n^2 + ω_n^2} \cdot \frac{s}{z}
  \eqqcolon
  G_1(s) + G_1(s) \frac{s}{z}
$$
where $G_1(s)$ is the standard second-order system without a zero.
Thus, the step response of the system is
$$
  Y(s) = U(s) G(s) 
  = 
  U(s) G_1(s) + U(s) G_1(s) \frac{s}{z}
  =
  Y_1(s) + Y_1(s) \frac{s}{z}
$$
where $Y_1(s)$ is the step response of the TF with no zeros. Hence,
$$
  y(t) = y_1(t) + \frac{1}{z} \frac{dy_1(t)}{dt}.
$$
Since $y_1(t)$ is increasing for small $t$, the derivative $dy_1(t)/dt$ is positive and therefore the second term leads to a faster and larger overshoot. 

The above formula also shows that when $z$ is large, then $y(t) \approx y_1(t)$.


### Impact of zero in the right-hand plane (non-minimum-phase system)

To understand this, we compare the response of two systems
$$
  \dfrac{8}{s^2 + 4s + 8}
  \quad\hbox{vs}\quad
  8 \cdot \dfrac{1-\frac{s}{z}}{s^2 + 4s + 8}
$$

```{julia}

using ControlSystems, DataFrames

# Use Float16 to reduce the size of data passed to OJS
df=DataFrame(z=Int[],time=Float16[],output=Float16[])

for z in 0:6
  if z == 0 
    G = tf(8 .* [1], [1,4,8])
  else
    G = tf(8 .* [-1/z,1], [1,4,8])
  end
  res = step(G,5)
  N = length(res.t)

  for n=1:N
    push!(df, (z=z, time=Float16(res.t[n]), output=Float16(res.y[n])))
  end
end

ojs_define(second_order_non_min_zero = df)
```

```{ojs}
viewof zero_non_min = Object.assign(Inputs.range([1,6], {label: "z", step: 1, value: 1 }), {style: '--label-width:20px'})
```
```{ojs}
//| layout-ncol: 2
//| label: fig-second-order-with-non-min-zero
//| fig-cap: Step response of a seocnd order system for different values zero. The orange curve shows the step response of a system without zero and the blue curve shows the step response of the system with zeros.

PZplot(
       [ {σ: zero_non_min, jω: 0} ], 
       [ {σ: -2, jω: 2}, {σ: -2, jω: -2} ],
       [-3, 6.5],
       [-3, 3],
      )

Plot.plot({
  grid: true,
  y: { domain: [-1.6, 1.2] },
  x: { domain: [0,5] },
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    Plot.line(second_order_non_min_zero.filter(d => d.z == zero_non_min), 
              {x:"time", y:"output", stroke: "darkblue" }),
    Plot.line(second_order_non_min_zero.filter(d => d.z == 0), 
              {x:"time", y:"output", stroke: "orange" })
  ]
})
```

The above example shows that a zero in the RHP leads to _undershoot_ and 
as the zero moves to infinity, the response approaches that of a system with no zeros. 

To understand why this is the case, we can follow the same analysis as for the minimal phase system to conclude that
$$
  y(t) = y_1(t) - \frac{1}{z} \frac{dy_1(t)}{dt}.
$$
Since $y_1(t)$ is increasing for small $t$, the derivative $dy_1(t)/dt$ is positive and therefore the second term leads to an undershoot. The above formula also shows that when $z$ is large, then $y(t) \approx y_1(t)$.

## Step response of critically damped second order system

## Step response of overdamped second order system
