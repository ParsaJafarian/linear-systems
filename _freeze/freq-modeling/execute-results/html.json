{
  "hash": "5d7a1b032ee96cd08afe906e7ba08bfd",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: Frequency domain modeling\n\nengine: julia\nexecute:\n  echo: false\n  freeze: true\n  cache: true\n---\n\n:::{.callout-note icon=false appearance=\"simple\"}\n## <i class=\"bi bi-journal-text text-primary\"></i> A comment about notation\nIn Signals and Systems, we used $u(t)$ to denote the step function. In this course, we will use $u(t)$ to denote the control input. So, to avoid confusion, we will use $\\mathbb{1}(t)$ to denote the step function. _Note that the book uses $u(t)$, which can get confusing, in my opinion._\n:::\n\nIn this lecture, we will review frequency domain modeling of LTI (linear and time invariant) systems. You have seen this material in Signals and Systems. The purpose of this review is to simply introduce the notation used in this course, in case it happens to be different from the notation used in Signals and Systems. You are strongly encouraged to review your notes on this topic.\n\n## Unilateral Laplace Transforms\n\nRecall that there are two types of Laplace transforms (LTs): bi-lateral or two-sided LTs and unilateral or one-sided LTs. In this course, we will work exclusively with unilateral LTs.\n\nAlso recall that for two-sided LTs, we need to worry about the ROC (region of convergence). For one-sided LTs, we never explicitly mention the ROC since it is always the right hand plane right to the rightmost pole. \n\nWe will use the notation\n$$f(t) \\xleftrightarrow{\\quad\\mathcal L\\quad} F(s)$$\nto denote a LT-pair. We will also use\n$$F(s) = \\mathcal{L}\\{ f(t)\\}$$\nor\n$$f(t) = \\mathcal L^{-1}\\{F(s)\\}$$\nwhen we want to explicitly write the LT or the inverse LT of a signal.\n\n---\n\nThe basic formula for a unilateral LT is\n$$F(s) = \\int_{0-}^{\\infty} f(t)e^{-st} dt.$$\nThe inverse Laplace transform is given by\n$$f(t) = \\frac{1}{2\\pi j} \\int_{\\sigma - j \\infty}^{\\sigma + j \\infty} F(s) e^{st} ds$$\nwhere $\\sigma$ is chosen such that $(\\sigma,0)$ is in the ROC. \n\nIn this course, we will **never** explicitly use these formulas to compute LTs. We will **always** use LT tables. You do not need to memorize the LT table; one will be provided during the examples. What you do need is the understanding of how to use the LT tables to compute LTs of complicated expressions and to compute inverse LTs using partial fraction expansion.\n\nI will not review this material in class. Please go back to your SS notes or review Sec 2.1--2.2 of the textbook. In is important to understand the following three cases:\n\n1. Roots of the denominator are real and distinct\n2. Roots of the denominator are complex and distinct\n3. Roots of the denominator are real and repeated. \n\n\n## The Transfer Function\n\nIn this course, we will work exclusively with LTI systems. Such systems arise in all branches of engineering, e.g., electrical circuits, spring-mass systems, gear systems, and thermodynamics. See Chapter 2 of Nice for detailed modeling examples. \n\nConsider an LTI system with input $u(t)$ (also called the reference signal sometimes) and output $y(t)$. We can also represent this as the following block diagram:\n\n![An LTI System](figures/svg/interconnect1.svg){#fig-LTI}\n\nAll such systems can be represented by constant coefficient linear differential equations (LDE) of the form\n$$\na_n \\frac{d^n y(t)}{dt^n}  + a_{n-1} \\frac{d^{n-1} y(t)}{dt^{n-1}} + \\cdots  a_0 y(t)\n= b_m \\frac{d^m u(t)}{dt^m} + b_{m-1} \\frac{d^{m-1} u(t)}{dt^{m-1}} + \\cdots + b_0 u(t).\n$$\n\n- This differential equation is called **linear** because there are no non-linear or multiplicative terms of the form $\\displaystyle \\left(\\frac{d^3 y(t)}{dt^3}\\right)\\left(\\frac{d^2 y(t)}{dt^2}\\right)$. \n\n- It is called **constant coefficient** because the coefficients $a_n$ and $b_m$ are constants that do not depend on time.\n\nThere is a one-to-one correspondence between constant coefficient LDE and an LTI system. That is, every LTI system can be described by a constant coefficient LDE and vice-versa. \n\nRecall that a key defining property of an LTI system is its impulse response, which we will typically denote by $g(t)$ and the transfer function, which we denote by $G(s)$. Recall that $g(t) \\xleftrightarrow{\\quad \\mathcal L \\quad} G(s)$. \n\nNow an interesting feature of a constant coefficient LDE is that we can identify the transfer function simply by inspection. \n\n![An LTI System](figures/svg/interconnect2.svg){#fig-LTI-s}\n\nGiven an LTI system with input $u(t)$ and output $y(t)$, we know that\n$$Y(s) = G(s)U(s).$$\nTherefore, if we know the input and output, we can identify the transfer function using\n$$ G(s) = \\frac{Y(s)}{U(s)}.$$\nNow, if we go back to the general formula of a constant coefficient LDE \n$$\na_n \\frac{d^n y(t)}{dt^n}  + a_{n-1} \\frac{d^{n-1} y(t)}{dt^{n-1}} + \\cdots  a_0 y(t)\n= b_m \\frac{d^m u(t)}{dt^m} + b_{m-1} \\frac{d^{m-1} u(t)}{dt^{m-1}} + \\cdots + b_0 u(t).\n$$\nand assume that the system starts from zero-initial state and take the LT of both sides, we get\n$$\na_n s^n Y(s) + a_{n-1} s^{n-1} Y(s) + \\cdots + a_0 Y(s)\n=\nb_m s^m U(s) + b_{m-1} s^{m-1} U(s) + \\cdots + b_m U(s).\n$$\nRearranging terms, we get\n$$\n(a_n s^n + a_{n-1} s^{n-1} + \\cdots + a_0) Y(s)\n=\n(b_m s^m + b_{m-1}s^{m-1} + \\cdots + b_0) U(s).\n$$\nTherefore,\n$$\nG(s) = \\frac{Y(s)}{U(s)}\n= \\frac{b_m s^m + b_{m-1} s^{m-1} + \\cdots + b_m}\n{a_n s^n + a_{n-1} s^{n-1} + \\cdots + a_0}.\n$$\nThus, we can easily go back and forth between the DE and the transfer function.\n\n:::{#exr-LDE-TF}\nFind the transfer function corresponding to the following LDE\n$$\n\\frac{d}{dt}y(t) + 2 y(t) = u(t)\n$$\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### Solution\nFrom inspection, we have\n$$G(s) = \\frac{1}{s + 2}$$\n:::\n\n:::{#exr-LDE-TF}\nFind a LDE that implements the following TF\n$$\nG(s) = \\frac{2s+1}{s^2 + 2s + 3}.\n$$\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### Solution\nFrom inspection, we have\n$$\n\\frac{d^2c(t)}{dt} + 2\\frac{d y(t)}{dt} + 3c(t) = 2\\frac{d u(t)}{dt} + u(t).\n$$\n:::\n\nIn this course, we will assume that the system is specified either as a LDE or as a TF. The textbook provides detailed examples of how to derive either the LDE or the TF from a physical system such as an electric circuit or a spring-mass system. \n\nWe present an alternative representation of the TF (pole-zero plot) in the next section. Later in the course we will also study other equivalent forms of representing the system such as state space equations and Bode plots.\n\nA final remark. In all the systems that we consider in this course, we will assume that $m < n$. So, the denominator of the TF has a strictly higher degree than the numerator. Such transfer functions are called **proper**. It is possible to have causal systems where $m=n$ but we will not consider that in this course. As a consequence, when we consider state space representation in future lectures, we will get formulas which are simpler than more general formulas which you may find at other sources. \n\n## Poles and Zeros of a Transfer Function\n\nThe TF of an LTI system is always of the form:\n$$\nG(s) \n= \\frac{b_m s^m + b_{m-1} s^{m-1} + \\cdots + b_m}\n{a_n s^n + a_{n-1} s^{n-1} + \\cdots + a_0}.\n$$\n\nBoth the numerator and the denominator are polynomials in $s$. So, we can factorize them and write the TF as \n$$\nG(s) \n= K\n\\frac{(s-z_1)(s-z_2) \\cdots (s - z_m)}\n{(s-p_1)(s-p_2)\\cdots (s-p_n)}.\n$$\n\n- The roots of the numerator are called **zeros** (because $G(z_i) = 0$). \n- The roots of the denominator are called **poles** (because $G(p_i) = \\infty$ and if we plot $G(s)$ it will have a peak going to $∞$ at $p_i$; this peak looks like a pole). \n- The constant $K$ is called the **gain** (because, when none of the poles and zeros are at origin, the step response of $G(s)$ will have a steady state value of $K$). \n\nWe often represent the poles and zeros using a **pole-zero plot.**\n\n```{ojs}\nPZplot = function(zeros, poles, xdomain, ydomain) {\n  return Plot.plot({\n    grid: true,\n    x: { domain: xdomain},\n    y: { domain: ydomain},\n\n    marks: [\n      // Axes\n      Plot.ruleX([0]),\n      Plot.ruleY([0]),\n      // Data\n      Plot.dot(zeros, {x:\"σ\", y:\"jω\", r: 5}),\n      Plot.dot(poles, {x:\"σ\", y:\"jω\", symbol: \"times\", r: 5}),\n    ]\n  })\n}\n```\n\n::: {#exm-pole-zero}\n#### Pole-zero plot\nConsder\n$$G(s) = \\frac{s+2}{(s+1)^2 + 1^2}.$$\nThe poles are $-1 \\pm j$ and the zero is $-2$. The pole-zero plot is shown below, where the location of the pole is represented by a \"cross\" and the location of the zero is represented by a \"circle\". \n\n```{ojs}\nPZplot(\n       [ {σ: -2, jω: 0} ], \n       [ { σ: -1, jω: -1 }, {σ: -1, jω: 1 } ],\n       [-3, 3],\n       [-3, 3],\n      )\n```\n:::\n\nSince the polynomials in the numerator and denominator of $G(s)$ have real coefficients, the roots are either real or occur in complex conjugate pairs. So, the poles and zeros either lie on the $σ$-axis or are symmetric about the $σ$-axis. \n\nNote that the pole-zero plot does not capture the gain of the TF. \n\n\n## BIBO Stability\n\nRecall from Signals and Systems that an LTI system with impulse response $g(t)$ is BIBO stable if\n$$\n\\int_{-∞}^{∞} |g(t)| dt < \\infty.\n$$\n\nFor a causal system (i.e., a system for which $g(t) = 0$ for $t < 0$), this is equivalent to \n$$\n\\int_{0^{-}}^{∞} |g(t)| dt < ∞.\n$$\n\nThis implies that for any $σ \\in \\reals$, $σ > 0$, we have \n$$\n\\int_{0^{-}}^{∞} |g(t)| e^{-σt} dt < ∞. \n$$\n\nTherefore, there can be no pole in the open right hand plane $\\{ (σ + j ω) : σ > 0 \\}$. Thus, we have the following:\n\n> A causal LTI system is stable if all poles are in the open left hand plane. \n\n```{ojs}\n//| layout-ncol: 2 \n//| fig-cap: Illustration of stable and unstable systems\n//| fig-subcap:\n//|     - Stable systems\n//|     - Unstable systems\n//|     - Marginally systems\n//|     - Unstable systems (double pole at origin)\n\nPZplot(\n       [ {σ: 1.5, jω: 0} ], \n       [ { σ: -1, jω: -1 }, {σ: -1, jω: 1 }, {σ: -1.5, jω: 0} ],\n       [-2, 2],\n       [-2, 2],\n      )\n\nPZplot(\n       [ {σ: -1.5, jω: 0} ], \n       [ { σ: -1, jω: -1 }, {σ: -1, jω: 1 }, { σ: 1.5, jω: 0 } ],\n       [-2, 2],\n       [-2, 2],\n      )\n\nPZplot(\n       [ {σ: 1.5, jω: 0} ], \n       [ { σ: -1, jω: -1 }, {σ: -1, jω: 1 }, {σ: 0, jω: 0} ],\n       [-2, 2],\n       [-2, 2],\n      )\n\nPZplot(\n       [ {σ: 1.5, jω: 0} ], \n       [ { σ: -1, jω: -1 }, {σ: -1, jω: 1 }, {σ: -0.02, jω: 0}, {σ: 0.02, jω: 0} ],\n       [-2, 2],\n       [-2, 2],\n      )\n\n```\n\nIf there are poles on the $j ω$ axis and the poles have multiplicity 1, then the system is **marginally stable**; if poles have multiplicity greater than 1, then the system is unstable.\n\nIn the next lecture, we will see how to use the poles to identify the step response of the system.\n\n## Step Response\n\nOne of the configurations that we will really focus on in the course is the output of a _stable_ system when the **input is a step function.** This is often the case when we specify a reference input such as the desired temperature of a room or the desired speed in cruise control of a car, and are interested in seeing if we get a \"good\" output. Note that this question is only of interest for stable systems. If the system is unstable, then the output will go to infinity. \n\nAs an example, consider the system of @exr-LDE-TF. What is the output when the input is a step function (assuming that the system starts from a zero initial state)?\n\nTo compute this, recall\n$$\n\\mathbb{1}(t) \\xleftrightarrow{\\quad \\mathcal L\\quad} \\frac 1s.\n$$\n\nThus, $U(s) = 1/s$. We had already identified that $G(s) = 1/(s+2)$. Thus,\n\\begin{align*}\nY(s) &= G(s) U(s) \\\\\n     &= \\frac{1}{s(s+2)} \\\\\n     &= \\frac{ \\frac 12 }{s} - \\frac{ \\frac 12 }{ s + 2 }\n     \\quad \\text{[By partial fraction expansion]}.\n\\end{align*}\nThus,\n$$\n  y(t) = \\left[ \\frac 12 - \\frac 12 e^{-2t} \\right] \\mathbb{1}(t).\n$$\n\n## Interconnection of LTI Systems\n\nThere are three common ways to inter connect LTI systems shown below.\n\n![Cascade Connection equivalent to $G_1(s)G_2(s)$.](figures/svg/interconnect3.svg){#fig-cascade}\n\n![Parallel Connection equivalent to $G_1(s) + G_2(s)$.](figures/svg/interconnect4.svg){#fig-parallel}\n\n![Feedback Connection equivalent to $\\displaystyle \\frac{G(s)}{1 + G(s)H(s)}$.](figures/svg/interconnect5.svg){#fig-feedback}\n\n## Time-delay systems\n\nIn a real system, there is often a delay between input and output, which is often modeled by a delay block whose output $y(t)$ is a delayed version of the input $u(t)$, by a delay time $τ$, that is\n$$\n  y(t) = u(t-τ).\n$$\nTaking the Laplace transform of both sides, we get\n$$\nY(s) = e^{-τs}U(s).\n$$\nTherefore, the TF of time-delay unit is $e^{-τs}$, which is different from the TFs studied so far as it is not a rational polynomial of $s$. It is possible to approximate $e^{-τs}$ using a rational polynomial using what is called [**Padé approximation**](https://en.wikipedia.org/wiki/Pad%C3%A9_approximant):\n\n- **First-order Padé approximation:**\n  $$ e^{-τs} \\approx \\dfrac{1 - τs/2}{1 + τs/2}. $$\n\n- **Second-order Padé approximation:**\n  $$ e^{-τs} \\approx \\dfrac{1 - τs/2 + (τs)^2/12}{1 + τs/2 + (τs)^2/12}. $$\n\nWe will not study time-delay systems in the course.\n\n",
    "supporting": [
      "freq-modeling_files"
    ],
    "filters": [],
    "includes": {}
  }
}